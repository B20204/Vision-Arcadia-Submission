{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "transferlearning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1FLbhcJFGYgynPsV3SI5p3hjUpPq-FJhI",
      "authorship_tag": "ABX9TyM+X2JTOrlH8ODv38YkjY3k",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/B20204/Vision-Arcadia-Submission/blob/main/transferlearning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-I8NBYhu37i"
      },
      "source": [
        "# Transfer Learning Model\n",
        "\n",
        "Here is our notebook on the transfer learning model , we have used [Mobilenet](https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4) model , we have used tensorflow hub to import the model , as far as the model is concerned its pretty simple , we have just added a final out layer with softmax activation fxn to recive probablity outputs. also since the model requires input in 224 x 224 we load the data in that particular size."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzMD9OXdSkoi"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, GlobalAveragePooling2D, Concatenate, Input,AveragePooling2D\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow_hub as hub\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import os"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHcI3VMgSwjV"
      },
      "source": [
        "def preprocess(img):\n",
        "  blur = cv2.GaussianBlur(img, (1,1), 0)\n",
        "  kernel = np.array([[-1, -1, -1],[-1, 8,-1],[-1, -1, -1]])\n",
        "  mask = cv2.filter2D(src=blur, ddepth=-1, kernel=kernel)\n",
        "  return mask\n",
        "\n",
        "def normalizeImg(img):\n",
        "  return img/255"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "esDZRrsIS3xm"
      },
      "source": [
        "book = {\n",
        "        0:('/content/drive/MyDrive/Gesture_Data/thumbs up/','Thumbs up'),\n",
        "        1:('/content/drive/MyDrive/Gesture_Data/w','W'),\n",
        "        2:('/content/drive/MyDrive/Gesture_Data/one','one'),\n",
        "        3:('/content/drive/MyDrive/Gesture_Data/Ok_gesture','ok'),\n",
        "        4:('/content/drive/MyDrive/Gesture_Data/V_gesture','V'),\n",
        "}\n",
        "\n",
        "numOfGestures = 5\n",
        "imgSize = 224"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0yrQhh1TFsN"
      },
      "source": [
        "x = []\n",
        "y = []\n",
        "\n",
        "for j in range(numOfGestures):\n",
        "  for i in os.listdir(book[j][0]):\n",
        "    \n",
        "    img = cv2.imread(os.path.join(book[j][0],i))\n",
        "    img = cv2.resize(img,(imgSize,imgSize))\n",
        "    img = normalizeImg(img)\n",
        "    x.append(img)\n",
        "    y.append(j)\n",
        "\n",
        "\n",
        "x = np.array(x)\n",
        "y = np.array(y)\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6KGdD_hXS-C"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=42)\n",
        "y_train = tf.one_hot(np.array(y_train).reshape(-1), numOfGestures)\n",
        "y_test = tf.one_hot(np.array(y_test).reshape(-1), numOfGestures)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYCyrgjQcZWN",
        "outputId": "d1ea8adf-8940-4953-9f46-7bfb88ed3095"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(623, 224, 224, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKYSMj6nTNHF",
        "outputId": "206304df-4c48-495f-8370-f20c3e6f5b21"
      },
      "source": [
        "transferLearningModel = tf.keras.Sequential([tf.keras.layers.InputLayer(input_shape=(224,224,3)),\n",
        "    hub.KerasLayer(\"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\", output_shape=[1280],\n",
        "                   trainable=False), \n",
        "    \n",
        "    tf.keras.layers.Dense(numOfGestures, activation='softmax')\n",
        "])\n",
        "\n",
        "transferLearningModel.compile(loss='categorical_crossentropy',optimizer=\"adam\", metrics=['accuracy'])\n",
        "transferLearningModel.fit(x=X_train, y=y_train, epochs=10)\n",
        "\n",
        "loss,acc = transferLearningModel.evaluate(x=X_test, y=y_test)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "20/20 [==============================] - 20s 796ms/step - loss: 1.6642 - accuracy: 0.2937\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 16s 794ms/step - loss: 1.1614 - accuracy: 0.5714\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 16s 778ms/step - loss: 0.9414 - accuracy: 0.6613\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 16s 779ms/step - loss: 0.7759 - accuracy: 0.7640\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 16s 779ms/step - loss: 0.6465 - accuracy: 0.8266\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 16s 784ms/step - loss: 0.5879 - accuracy: 0.8459\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 16s 777ms/step - loss: 0.5100 - accuracy: 0.8732\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 16s 776ms/step - loss: 0.4534 - accuracy: 0.9037\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 16s 777ms/step - loss: 0.4168 - accuracy: 0.9037\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 16s 776ms/step - loss: 0.3770 - accuracy: 0.9294\n",
            "3/3 [==============================] - 2s 500ms/step - loss: 0.7392 - accuracy: 0.7571\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKuf4VIea_Ti",
        "outputId": "5d24ae84-b3a3-49d9-c67d-02ac5d87ce5f"
      },
      "source": [
        "transferLearningModel.save('/content/drive/MyDrive/Gesture_Data/transferLearningModel/tl_model')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Gesture_Data/transferLearningModel/tl_model/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Gesture_Data/transferLearningModel/tl_model/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GLRqUUpsnM3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04e6608c-01f8-4e6d-ce93-937dce5973df"
      },
      "source": [
        "model2 = tf.keras.models.load_model('/content/drive/MyDrive/Gesture_Data/transferLearningModel/tl_model')\n",
        "model2.evaluate(X_test,y_test)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 2s 495ms/step - loss: 0.5770 - accuracy: 0.8143\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5769751071929932, 0.8142856955528259]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    }
  ]
}